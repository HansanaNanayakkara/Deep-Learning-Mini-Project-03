{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HansanaNanayakkara/Deep-Learning-Mini-Project-03/blob/main/English_to_Sinhala_Translator_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SuIGuO0AEcz_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m6z4UcBdE3Ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f319f6b-9ef6-4a8e-9f17-89fa24ff6ae0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = \"/content/drive/My Drive/DL Mini project 3/English-Sinhala - Copy.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "i = 0\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  i = i + 1\n",
        "  if(i==453):\n",
        "    break"
      ],
      "metadata": {
        "id": "ag1ubwSlE6cX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a616aa-ec9b-4411-f6ac-a4d9ec3119b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You|ඔබ\n",
            "I|මම\n",
            "Here|මෙතන\n",
            "We|අප\n",
            "He|ඔහු\n",
            "She|ඇය\n",
            "Live|සජීවි\n",
            "Study|අධ්‍යයනය කරන්න\n",
            "Go|යන්න\n",
            "dog|බල්ලා\n",
            "cat|බළලා\n",
            "Ball|පන්දුව\n",
            "house|නිවස\n",
            "tree|ගස\n",
            "run|දුවනවා\n",
            "jump|පනින්න\n",
            "happy|සතුටු\n",
            "sad|දුක\n",
            "big|ලොකු\n",
            "small|කුඩා\n",
            "fast|ඉක්මනින්\n",
            "slow|මන්දගාමී\n",
            "red|රතු\n",
            "blue|නිල්\n",
            "green|කොළ\n",
            "yellow|කහ\n",
            "eat|කනවා\n",
            "drink|බොනවා\n",
            "sleep|නිදාගන්නවා\n",
            "wake|අවදි කරනවා\n",
            "book|පොත\n",
            "pen|පෑන\n",
            "paper|කඩදාසි\n",
            "chair|පුටුව\n",
            "table|වගුව\n",
            "car|මෝටර් රථය\n",
            "bike|බයිසිකලය\n",
            "walk|ඇවිදින්න\n",
            "talk|කතා කරනවා\n",
            "laugh|හිනා වෙනවා\n",
            "cry|අඬනවා\n",
            "smile|සිනහව\n",
            "frown|රවනවා\n",
            "door|දොර\n",
            "window|කවුළුව\n",
            "computer|පරිගණක\n",
            "phone|දුරකථන\n",
            "read|කියවනවා\n",
            "write|ලියනවා\n",
            "Sing|ගයනවා\n",
            "dance|නටනවා\n",
            "hear|අහන්න\n",
            "see|බලන්න\n",
            "touch|ස්පර්ශ කරනවා\n",
            "taste|රස\n",
            "smell|සුවඳ\n",
            "good|යහපත\n",
            "bad|නරක\n",
            "right|හරි\n",
            "wrong|වැරදි\n",
            "up|දක්වා\n",
            "down|පහළ\n",
            "in|තුල\n",
            "out|පිටතට\n",
            "on|මත\n",
            "off|අක්‍රිය\n",
            "near|අසල\n",
            "far|දුරින්\n",
            "there|එතන\n",
            "now|දැන්\n",
            "then|ඉන්පසු\n",
            "day|දවස\n",
            "night|රෑ\n",
            "sun|හිරු\n",
            "moon|සඳ\n",
            "star|තරුව\n",
            "sky|අහස\n",
            "cloud|වලාකුළු\n",
            "rain|වැස්ස\n",
            "snow|හිම\n",
            "wind|සුළඟ\n",
            "hot|උණුසුම්\n",
            "cold|සීතලයි\n",
            "summer|ගිම්හානය\n",
            "winter|ශීත ඍතුව\n",
            "spring|වසන්තය\n",
            "autumn|සරත් ඍතුව\n",
            "fall|වැටෙනවා\n",
            "year|අවුරුදු\n",
            "month|මස\n",
            "week|සතිය\n",
            "day|දවස\n",
            "hour|පැය\n",
            "minute|මිනිත්තුව\n",
            "second|තත්පර\n",
            "yesterday|ඊයේ\n",
            "today|අද\n",
            "tomorrow|හෙට\n",
            "always|සැමවිටම\n",
            "never|කවදාවත් නෑ\n",
            "sometimes|සමහර විට\n",
            "often|බොහෝ විට\n",
            "rarely|කලාතුරකින්\n",
            "Quickly|ඉක්මනින්\n",
            "Slowly|සෙමින්\n",
            "Loudly|හයියෙන්\n",
            "Softly|මෘදු ලෙස\n",
            "Soon|ඉක්මනින්\n",
            "later|පසු\n",
            "now|දැන්\n",
            "then|ඉන්පසු\n",
            "before|කලින්\n",
            "after|අනතුරුව\n",
            "first|පලමු\n",
            "last|අවසන්\n",
            "one|එක\n",
            "two|දෙක\n",
            "three|තුන\n",
            "four|සිව්\n",
            "five|පහ\n",
            "six|හය\n",
            "seven|හත\n",
            "eight|අට\n",
            "nine|නවය\n",
            "ten|දහය\n",
            "eleven|එකොළොහ\n",
            "twelve|දොළොස්\n",
            "twenty|විස්ස\n",
            "thirty|තිස්\n",
            "forty|හතළිහක්\n",
            "fifty|පනස්\n",
            "sixty|හැට\n",
            "seventy|හැත්තෑ\n",
            "eighty|අසූව\n",
            "Ninety|අනූව\n",
            "hundred|සියය\n",
            "thousand|දහස\n",
            "million|මිලියන\n",
            "billion|බිලියන\n",
            "father|පියා\n",
            "mother|මව\n",
            "brother|සහෝදරයා\n",
            "sister|සහෝදරිය\n",
            "son|පුතා\n",
            "daughter|දියණිය\n",
            "aunt|නැන්දා\n",
            "uncle|මාමා\n",
            "cousin|මස්සිනා\n",
            "grandmother|ආච්චි\n",
            "grandfather|සීයා\n",
            "nephew|බෑණා\n",
            "niece|ලේලිය\n",
            "friend|මිතුරා\n",
            "enemy|සතුරා\n",
            "teacher|ගුරු\n",
            "student|ශිෂ්යයා\n",
            "doctor|වෛද්යවරයා\n",
            "nurse|හෙදිය\n",
            "policeman|පොලිස්කාරයා\n",
            "firefighter|ගිනි නිවන භටයා\n",
            "astronaut|ගගනගාමියා\n",
            "pilot|නියමුවා\n",
            "chef|චෙෆ්\n",
            "farmer|ගොවියා\n",
            "scientist|විද්යාඥයා\n",
            "engineer|ඉංජිනේරු\n",
            "artist|කලාකරු\n",
            "musician|සංගීතඥයා\n",
            "actor|නළුවා\n",
            "actress|නිළිය\n",
            "writer|ලේඛකයා\n",
            "poet|කවියා\n",
            "athlete|මලල ක්රීඩකයා\n",
            "baker|බේකර්\n",
            "barber|බාබර්\n",
            "carpenter|වඩු කාර්මිකයා\n",
            "dentist|දන්ත වෛද්යවරයා\n",
            "electrician|විදුලි කාර්මිකයා\n",
            "gardener|උයන්පල්ලා\n",
            "hairdresser|කොණ්ඩා මෝස්තරකරු\n",
            "journalist|මාධ්යවේදී\n",
            "lawyer|නීතිඥයා\n",
            "mechanic|යාන්ත්රික\n",
            "plumber|ජලනල කාර්මිකයා\n",
            "sailor|නාවිකයා\n",
            "Soldier|සොල්දාදුවා\n",
            "tailor|ටේලර්\n",
            "waiter|වේටර්\n",
            "waitress|වේටර්වරියක්\n",
            "clerk|ලිපිකරු\n",
            "cashier|අයකැමි\n",
            "receptionist|පිළිගැනීමේ නිලධාරියා\n",
            "librarian|පුස්තකාලයාධිපති\n",
            "coach|පුහුණුකරුවා\n",
            "referee|විනිසුරු\n",
            "captain|කපිතාන්\n",
            "king|රජ\n",
            "queen|රැජින\n",
            "prince|කුමාරයා\n",
            "princess|කුමරිය\n",
            "president|ජනාධිපති\n",
            "vice-president|උප ජනාධිපති\n",
            "mayor|නගරාධිපති\n",
            "governor|ආණ්ඩුකාර\n",
            "senator|සෙනෙට් සභිකයා\n",
            "congressman|කොන්ග්රස්කාරයා\n",
            "lawyer|නීතිඥයා\n",
            "judge|විනිශ්චය කරන්න\n",
            "detective|රහස් පරීක්ෂකයා\n",
            "criminal|අපරාධ\n",
            "victim|ගොදුර\n",
            "thief|හොරා\n",
            "robber|හොරා\n",
            "burglar|ගෙවල් බිදින්නා\n",
            "spy|ඔත්තු බලන්න\n",
            "terrorist|ත්රස්තවාදී\n",
            "hostage|ප්රාණ ඇපකරු\n",
            "criminal|අපරාධ\n",
            "prisoner|සිරකරුවා\n",
            "Convict|වරදකරු\n",
            "jail|හිරගෙදර\n",
            "prison|බන්ධනාගාර\n",
            "cell|සෛලය\n",
            "crime|අපරාධය\n",
            "robbery|මංකොල්ලකෑම\n",
            "theft|සොරකම\n",
            "burglary|සොරකම් කිරීම\n",
            "kidnapping|පැහැර ගැනීම\n",
            "murder|ඝාතනය\n",
            "assassination|ඝාතනය\n",
            "terrorism|ත්රස්තවාදය\n",
            "hostage|ප්රාණ ඇපකරු\n",
            "war|යුද්ධය\n",
            "battle|සටන\n",
            "fight|සටන් කරනවා\n",
            "attack|පහර දෙනවා\n",
            "defense|ආරක්ෂක\n",
            "peace|සාම\n",
            "love|ආදරය\n",
            "hate|වෛර කරනවා\n",
            "anger|කෝපය\n",
            "fear|බිය\n",
            "joy|සතුට\n",
            "sadness|දුක\n",
            "happiness|සතුට\n",
            "loneliness|තනිකම\n",
            "friendship|මිත්රත්වය\n",
            "relationship|සම්බන්ධතාවය\n",
            "marriage|විවාහ\n",
            "divorce|දික්කසාදය\n",
            "wedding|විවාහ\n",
            "funeral|අවමංගල්යය\n",
            "birthday|උපන් දිනය\n",
            "holiday|නිවාඩු\n",
            "vacation|නිවාඩු\n",
            "trip|සංචාරය\n",
            "journey|ගමන\n",
            "adventure|ත්රාසජනක\n",
            "discovery|සොයාගැනීම\n",
            "exploration|ගවේෂණය\n",
            "invention|නව නිපැයුම්\n",
            "innovation|නවෝත්පාදනය\n",
            "creation|නිර්මාණය\n",
            "destruction|විනාශය\n",
            "accident|අනතුර\n",
            "mistake|වැරැද්ද\n",
            "error|දෝෂය\n",
            "problem|ගැටලුව\n",
            "solution|විසඳුමක්\n",
            "question|ප්රශ්නය\n",
            "answer|පිළිතුර\n",
            "challenge|අභියෝගය\n",
            "difficulty|දුෂ්කරතාව\n",
            "obstacle|බාධාවක්\n",
            "barrier|බාධකයක්\n",
            "limit|සීමාව\n",
            "boundary|මායිම\n",
            "rule|නීතිය\n",
            "law|නීති\n",
            "regulation|නියාමනය\n",
            "guideline|මාර්ගෝපදේශය\n",
            "requirement|අවශ්යතාවය\n",
            "instruction|උපදෙස්\n",
            "command|විධානය\n",
            "order|නියෝග\n",
            "request|ඉල්ලීම\n",
            "suggestion|යෝජනාව\n",
            "advice|උපදෙස්\n",
            "warning|අනතුරු ඇඟවීම\n",
            "notice|දැනුම්දීම\n",
            "signal|සංඥාව\n",
            "symbol|සංකේතය\n",
            "sign|ලකුණ\n",
            "mark|ලකුණ\n",
            "label|ලේබලය\n",
            "tag|ටැගය\n",
            "price|මිල\n",
            "cost|පිරිවැය\n",
            "value|අගය\n",
            "worth|වටිනා\n",
            "benefit|ප්රතිලාභය\n",
            "advantage|වාසිය\n",
            "disadvantage|අවාසිය\n",
            "problem|ගැටලුව\n",
            "issue|කලාපය\n",
            "concern|සැලකිලිමත් වීම\n",
            "worry|කනස්සල්ල\n",
            "fear|බිය\n",
            "doubt|සැකය\n",
            "uncertainty|අවිනිශ්චිතතාවය\n",
            "risk|අවදානම්\n",
            "danger|අනතුර\n",
            "hazard|අනතුර\n",
            "threat|තර්ජනය\n",
            "safety|ආරක්ෂාව\n",
            "security|ආරක්ෂක\n",
            "protection|ආරක්ෂාව\n",
            "defense|ආරක්ෂක\n",
            "shield|පලිහ\n",
            "armor|සන්නාහය\n",
            "weapon|ගිනි අවියක්\n",
            "tool|මෙවලම\n",
            "equipment|උපකරණ\n",
            "gear|ගියර්\n",
            "device|උපාංගය\n",
            "machine|යන්ත්රය\n",
            "Engine|එන්ජිම\n",
            "motor|මෝටර්\n",
            "vehicle|වාහන\n",
            "car|මෝටර් රථ\n",
            "truck|ට්රක් රථය\n",
            "bus|බස්\n",
            "train|දුම්රිය\n",
            "airplane|ගුවන් යානය\n",
            "helicopter|හෙලිකොප්ටරය\n",
            "boat|බෝට්ටුව\n",
            "ship|නැව\n",
            "submarine|සබ්මැරීනය\n",
            "rocket|රොකට්\n",
            "spacecraft|අභ්යවකාශ යානා\n",
            "satellite|චන්ද්රිකාව\n",
            "robot|රොබෝ\n",
            "computer|පරිගණක\n",
            "laptop|ලැප්ටොප්\n",
            "tablet|ටැබ්ලට්\n",
            "smartphone|ස්මාර්ට් ජංගම දුරකථනය\n",
            "camera|කැමරා\n",
            "television|රූපවාහිනිය\n",
            "radio|ගුවන් විදුලි\n",
            "internet|අන්තර්ජාල\n",
            "website|වෙබ් අඩවිය\n",
            "social media|සමාජ මාධ්ය\n",
            "network|ජාල\n",
            "platform|වේදිකාව\n",
            "software|මෘදුකාංග\n",
            "program|වැඩසටහන\n",
            "application|අයදුම්පත\n",
            "app|යෙදුම\n",
            "game|ක්රීඩාව\n",
            "video game|වීඩියෝ ක්රීඩාව\n",
            "puzzle|ප්රහේලිකාව\n",
            "challenge|අභියෝගය\n",
            "competition|තරඟාවලිය\n",
            "tournament|තරඟය\n",
            "match|තරඟය\n",
            "race|තරඟය\n",
            "contest|තරඟය\n",
            "event|සිදුවීම\n",
            "ceremony|උත්සවය\n",
            "festival|උත්සවය\n",
            "celebration|සැමරුම\n",
            "party|පක්ෂය\n",
            "gathering|රැස් කිරීම\n",
            "meeting|රැස්වීම\n",
            "conference|සම්මන්ත්රණය\n",
            "seminar|සම්මන්ත්රණය\n",
            "workshop|වැඩමුළුව\n",
            "The dog runs.|බල්ලා දුවනවා.\n",
            "The cat sleeps.|බළලා නිදාගන්නවා.\n",
            "The ball is red.|පන්දුව රතු පාටයි.\n",
            "The house is big.|නිවස විශාලයි.\n",
            "The tree is green.|ගස කොළ පාටයි.\n",
            "I am happy.|මම සතුටින්.\n",
            "She is sad.|ඇය දුකින්.\n",
            "He is small.|ඔහු කුඩා ය.\n",
            "They are fast.|ඔවුන් වේගවත් ය.\n",
            "We are slow.|අපි මන්දගාමීයි.\n",
            "The big tree provides shade on sunny days.|විශාල ගස අව්ව සහිත දිනවල සෙවන සපයයි.\n",
            "She drinks cold water after a long run.|ඇය දිගු ගමනකින් පසු සිසිල් ජලය පානය කරයි.\n",
            "He reads books about space exploration.|ඔහු අභ්‍යවකාශ ගවේෂණ ගැන පොත් කියවනවා.\n",
            "They play with a red ball in the backyard.|ඔවුන් රතු බෝලයක් සමඟ පිටියේ සෙල්ලම් කරති.\n",
            "We laugh when we watch funny movies together.|අපි එකට විනෝදජනක චිත්‍රපට නරඹන විට අපි සිනාසෙමු.\n",
            "The dog barks loudly, yet the cat remains calm.|බල්ලා හයියෙන් බුරන නමුත් බළලා සන්සුන්ව සිටියි.\n",
            "She dances gracefully, but he moves awkwardly.|ඇය අලංකාර ලෙස නටන නමුත් ඔහු අපහසුවෙන් ගමන් කරයි.\n",
            "They study diligently, so they perform well in exams.|ඔවුන් උනන්දුවෙන් පාඩම් කරන නිසා විභාගවලින් දස්කම් දක්වති.\n",
            "He sings beautifully, or he plays the guitar skillfully.|ඔහු ලස්සනට ගායනා කරයි, නැතහොත් ඔහු දක්ෂ ලෙස ගිටාර් වාදනය කරයි.\n",
            "We eat dinner early, and then we go for a walk.|අපි රෑ කෑම වේලාසනින් කනවා, ඊට පස්සේ අපි ඇවිදින්න යනවා.\n",
            "The dog runs happily in the park.|බල්ලා උද්‍යානයේ සතුටින් දිව යයි.\n",
            "She drinks water from a blue cup.|ඇය නිල් කෝප්පයකින් වතුර බොනවා.\n",
            "He reads a book on the red chair.|ඔහු රතු පුටුව මත පොතක් කියවයි.\n",
            "They eat apples under the big tree.|ඔවුන් විශාල ගසක් යට ඇපල් කනවා.\n",
            "We laugh together at funny jokes.|අපි විහිලු විහිළුවලට එකට හිනා වෙනවා.\n",
            "The cat sleeps, and the dog plays outside.|බළලා නිදාගන්නවා, බල්ලා එළියේ සෙල්ලම් කරනවා.\n",
            "He runs fast, but she walks slowly.|ඔහු වේගයෙන් දුවන නමුත් ඇය ඇවිදින්නේ සෙමින්.\n",
            "They jump high, yet they land softly.|ඔවුන් ඉහළට පනිනවා, නමුත් ඔවුන් මෘදු ලෙස ගොඩ බසිනවා.\n",
            "She sings loudly, or she dances quietly.|ඇය හයියෙන් ගායනා කරයි, නැතහොත් ඇය නිහඬව නටයි.\n",
            "We laugh and cry at the same time.|අපි හිනාවෙලා අඩනවා එක පාරටම.\n",
            "Does the dog run faster than the cat?|බල්ලා බළලාට වඩා වේගයෙන් දුවනවාද?\n",
            "Is the ball blue or red?|පන්දුව නිල් හෝ රතුද?\n",
            "Where is the tree located?|ගස පිහිටා ඇත්තේ කොහේද?\n",
            "How big is the house?|නිවස කොතරම් විශාලද?\n",
            "What color is the chair?|පුටුවේ වර්ණය කුමක්ද?\n",
            "Can you see the stars at night?|රෑට තරු පේනවාද?\n",
            "Who is happy?|සතුටු වන්නේ කවුද?\n",
            "Why is she sad?|ඇය දුක් වන්නේ ඇයි?\n",
            "When do you usually wake up?|ඔබ සාමාන්‍යයෙන් අවදි වන්නේ කවදාද?\n",
            "Do you have a pen?|ඔබට පෑනක් තිබේද?\n",
            "Who is sitting at the table?|මේසයේ වාඩි වී සිටින්නේ කවුද?\n",
            "What do you eat for breakfast?|ඔබ උදේ ආහාරය සඳහා කන්නේ කුමක්ද?\n",
            "How do you travel to work?|ඔබ රැකියාවට යන්නේ කෙසේද?\n",
            "Is it raining outside?|එළියේ වැස්සද?\n",
            "When is your birthday?|ඔයාගේ උපන් දිනය කවදා ද?\n",
            "What time does the movie start?|චිත්රපටය ආරම්භ වනුයේ කීයටද?\n",
            "Are you going on vacation this year?|ඔබ මේ වසරේ නිවාඩුවක් ගත කරනවාද?\n",
            "Where did you go last summer?|පසුගිය ගිම්හානයේදී ඔබ කොහෙද ගියේ?\n",
            "Who is your favorite actor?|ඔබේ ප්රියතම නළුවා කවුද?\n",
            "What is the capital of France?|ප්රංශයේ අගනුවර කුමක්ද?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs = []\n",
        "for line in lines:\n",
        "    if \"|\" in line:  # Check if the line contains the pipe character\n",
        "        english, sinhala = line.split(\"|\")\n",
        "        sinhala = \"[start] \" + sinhala.strip() + \" [end]\"  # Also, strip any leading/trailing whitespace\n",
        "        text_pairs.append((english.strip(), sinhala))\n",
        "    else:\n",
        "        print(f\"Ignoring line: {line.strip()} because it does not contain a pipe character.\")\n",
        "        continue  # Skip to the next iteration\n",
        "\n",
        "import random\n",
        "for i in range(3):\n",
        "    print(random.choice(text_pairs))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhBwukenGm_E",
        "outputId": "4bf534d3-15ce-4c59-afc1-4e3b2ce5f32b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I am happy.', '[start] මම සතුටින්. [end]')\n",
            "('last', '[start] අවසන් [end]')\n",
            "('contest', '[start] තරඟය [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(text_pairs)"
      ],
      "metadata": {
        "id": "SptBj6dXGsPW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n",
        "print(\"Total sentences:\",len(text_pairs))\n",
        "print(\"Training set size:\",len(train_pairs))\n",
        "print(\"Validation set size:\",len(val_pairs))\n",
        "print(\"Testing set size:\",len(test_pairs))"
      ],
      "metadata": {
        "id": "3V5d0eUQGsb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771cfba2-889f-447f-ca16-d192ef8e37ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 427\n",
            "Training set size: 299\n",
            "Validation set size: 64\n",
            "Testing set size: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")"
      ],
      "metadata": {
        "id": "Lv-ACn-xGshs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_sinhala_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_sinhala_texts)"
      ],
      "metadata": {
        "id": "pIgJcYyMGsmA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = source_vectorization(eng)\n",
        "    sin = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,\n",
        "        \"sinhala\": sin[:, :-1],\n",
        "    }, sin[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)  # Corrected variable name\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['sinhala'].shape: {inputs['sinhala'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n"
      ],
      "metadata": {
        "id": "wE7WR-cAGsoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8257804-f6fe-4acb-d462-9ccbc58328ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['sinhala'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "o-pw9cCFGssF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "WKs6-3njHfy0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "E8CliT0xHsi_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"sinhala\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer.summary()"
      ],
      "metadata": {
        "id": "0H2R8BF9HtvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d854ab-544d-4f7f-e041-fa161d99bb62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " sinhala (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            3845120   ['sinhala[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_1[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, None, 15000)          3855000   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=60, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "3fslJwVZH40v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d5c2d8-3a95-49e6-d4e4-dea14e494b07"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "5/5 [==============================] - 8s 362ms/step - loss: 1.1037 - accuracy: 0.8855 - val_loss: 5.2030 - val_accuracy: 0.3733\n",
            "Epoch 2/60\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 2.1071 - accuracy: 0.6951 - val_loss: 3.9075 - val_accuracy: 0.5622\n",
            "Epoch 3/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.9126 - accuracy: 0.9396 - val_loss: 3.7883 - val_accuracy: 0.5668\n",
            "Epoch 4/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.7015 - accuracy: 0.9725 - val_loss: 3.7705 - val_accuracy: 0.5899\n",
            "Epoch 5/60\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.5976 - accuracy: 0.9762 - val_loss: 3.7755 - val_accuracy: 0.5853\n",
            "Epoch 6/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.5255 - accuracy: 0.9789 - val_loss: 3.7736 - val_accuracy: 0.5760\n",
            "Epoch 7/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.4711 - accuracy: 0.9826 - val_loss: 3.7820 - val_accuracy: 0.5806\n",
            "Epoch 8/60\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.4011 - accuracy: 0.9826 - val_loss: 3.7840 - val_accuracy: 0.5853\n",
            "Epoch 9/60\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.3347 - accuracy: 0.9826 - val_loss: 3.8072 - val_accuracy: 0.5853\n",
            "Epoch 10/60\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.2923 - accuracy: 0.9853 - val_loss: 3.8261 - val_accuracy: 0.5853\n",
            "Epoch 11/60\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.2503 - accuracy: 0.9881 - val_loss: 3.8197 - val_accuracy: 0.5899\n",
            "Epoch 12/60\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.2225 - accuracy: 0.9844 - val_loss: 3.8493 - val_accuracy: 0.5899\n",
            "Epoch 13/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.1855 - accuracy: 0.9863 - val_loss: 3.8144 - val_accuracy: 0.5899\n",
            "Epoch 14/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.1653 - accuracy: 0.9872 - val_loss: 3.8173 - val_accuracy: 0.5899\n",
            "Epoch 15/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.1333 - accuracy: 0.9863 - val_loss: 3.8462 - val_accuracy: 0.5853\n",
            "Epoch 16/60\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.1139 - accuracy: 0.9872 - val_loss: 3.8655 - val_accuracy: 0.5853\n",
            "Epoch 17/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0978 - accuracy: 0.9918 - val_loss: 3.8768 - val_accuracy: 0.5853\n",
            "Epoch 18/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0855 - accuracy: 0.9890 - val_loss: 3.8678 - val_accuracy: 0.5899\n",
            "Epoch 19/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0736 - accuracy: 0.9927 - val_loss: 3.9037 - val_accuracy: 0.5853\n",
            "Epoch 20/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0629 - accuracy: 0.9890 - val_loss: 3.8951 - val_accuracy: 0.5853\n",
            "Epoch 21/60\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0555 - accuracy: 0.9908 - val_loss: 3.8944 - val_accuracy: 0.5899\n",
            "Epoch 22/60\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0479 - accuracy: 0.9936 - val_loss: 3.9071 - val_accuracy: 0.5714\n",
            "Epoch 23/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0467 - accuracy: 0.9927 - val_loss: 3.9191 - val_accuracy: 0.5899\n",
            "Epoch 24/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0418 - accuracy: 0.9954 - val_loss: 3.9465 - val_accuracy: 0.5945\n",
            "Epoch 25/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0355 - accuracy: 0.9936 - val_loss: 3.9644 - val_accuracy: 0.5991\n",
            "Epoch 26/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0322 - accuracy: 0.9945 - val_loss: 3.9764 - val_accuracy: 0.5899\n",
            "Epoch 27/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 3.9829 - val_accuracy: 0.5899\n",
            "Epoch 28/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0302 - accuracy: 0.9936 - val_loss: 3.9774 - val_accuracy: 0.5899\n",
            "Epoch 29/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 3.9728 - val_accuracy: 0.5899\n",
            "Epoch 30/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0214 - accuracy: 0.9973 - val_loss: 4.0169 - val_accuracy: 0.5899\n",
            "Epoch 31/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0187 - accuracy: 0.9973 - val_loss: 4.0132 - val_accuracy: 0.5945\n",
            "Epoch 32/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 4.0271 - val_accuracy: 0.5945\n",
            "Epoch 33/60\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 4.0223 - val_accuracy: 0.5853\n",
            "Epoch 34/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0143 - accuracy: 0.9982 - val_loss: 4.0000 - val_accuracy: 0.5945\n",
            "Epoch 35/60\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 4.0272 - val_accuracy: 0.5945\n",
            "Epoch 36/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 4.0675 - val_accuracy: 0.5945\n",
            "Epoch 37/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 4.0401 - val_accuracy: 0.5945\n",
            "Epoch 38/60\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.0389 - accuracy: 0.9945 - val_loss: 5.0137 - val_accuracy: 0.3871\n",
            "Epoch 39/60\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.5492 - accuracy: 0.9158 - val_loss: 4.0700 - val_accuracy: 0.5991\n",
            "Epoch 40/60\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0563 - accuracy: 0.9918 - val_loss: 4.0547 - val_accuracy: 0.5945\n",
            "Epoch 41/60\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 4.0432 - val_accuracy: 0.5991\n",
            "Epoch 42/60\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 4.0501 - val_accuracy: 0.5945\n",
            "Epoch 43/60\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 4.0534 - val_accuracy: 0.5945\n",
            "Epoch 44/60\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 4.0659 - val_accuracy: 0.5945\n",
            "Epoch 45/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 4.0908 - val_accuracy: 0.5945\n",
            "Epoch 46/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 4.1005 - val_accuracy: 0.5945\n",
            "Epoch 47/60\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 4.1117 - val_accuracy: 0.5945\n",
            "Epoch 48/60\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 4.1140 - val_accuracy: 0.5945\n",
            "Epoch 49/60\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 4.0848 - val_accuracy: 0.5945\n",
            "Epoch 50/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 4.1233 - val_accuracy: 0.5945\n",
            "Epoch 51/60\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 4.1416 - val_accuracy: 0.5945\n",
            "Epoch 52/60\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 4.1294 - val_accuracy: 0.5945\n",
            "Epoch 53/60\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 4.1593 - val_accuracy: 0.5945\n",
            "Epoch 54/60\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 4.1578 - val_accuracy: 0.5945\n",
            "Epoch 55/60\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 4.1650 - val_accuracy: 0.5945\n",
            "Epoch 56/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 4.1509 - val_accuracy: 0.5945\n",
            "Epoch 57/60\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 4.1732 - val_accuracy: 0.5945\n",
            "Epoch 58/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 4.1620 - val_accuracy: 0.5991\n",
            "Epoch 59/60\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 4.1656 - val_accuracy: 0.5945\n",
            "Epoch 60/60\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 4.1699 - val_accuracy: 0.6037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b5d2c1afb80>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sin_vocab = target_vectorization.get_vocabulary()\n",
        "sinh_index_lookup = dict(zip(range(len(sin_vocab)), sin_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = sinh_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))\n"
      ],
      "metadata": {
        "id": "Zkvvf73DH5uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf6ee00-3abd-4964-e203-b69fe93e65c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "protection\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "question\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "enemy\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "contest\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "vice-president\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "The big tree provides shade on sunny days.\n",
            "[start] බළලා නිදාගන්නවා බල්ලා එළියේ සෙල්ලම් කරනවා [end]\n",
            "-\n",
            "then\n",
            "[start] ඉන්පසු [end]\n",
            "-\n",
            "hundred\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "far\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "laptop\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "Go\n",
            "[start] ඔහු [end]\n",
            "-\n",
            "fear\n",
            "[start] බිය [end]\n",
            "-\n",
            "enemy\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "The dog runs happily in the park.\n",
            "[start] බල්ලා හයියෙන් බුරන නමුත් බළලා සන්සුන්ව සිටියි [end]\n",
            "-\n",
            "question\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "cashier\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "laptop\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "then\n",
            "[start] ඉන්පසු [end]\n",
            "-\n",
            "gathering\n",
            "[start] ආරක්ෂක [end]\n",
            "-\n",
            "eleven\n",
            "[start] ආරක්ෂක [end]\n"
          ]
        }
      ]
    }
  ]
}